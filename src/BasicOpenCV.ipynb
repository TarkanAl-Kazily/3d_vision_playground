{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Playground\n",
    "\n",
    "This notebook's goal is to get used to using OpenCV to work with basic images. It relies on images stored in the `data` directory.\n",
    "\n",
    "I've taken photos of my desktop monitor displaying a checkerboard pattern, and hopefully can do some useful camera calibration stuff with OpenCV's functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# My utility functions\n",
    "from utils import *\n",
    "\n",
    "# For timing tests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = \"Checkerboard/IMG_0821.jpg\"\n",
    "print(f\"Loading image {img_name}\")\n",
    "image = load_image(img_name)\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "image = convert_image_c2f(image)\n",
    "print(image.shape)\n",
    "print(image[0:5, 0:5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob_data(\"checkerboard_video/*\")\n",
    "for f in files:\n",
    "    img = load_image(f)\n",
    "    print(f\"img.shape {img.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image filters\n",
    "\n",
    "`cv2.filter2D` is OpenCV's implementation of applying an image filter, such as a sobel filter, to an image. It can be an effective way to find edges in an image, depending on the kernel used.\n",
    "\n",
    "A good source to learn about kernels is [Wikipedia](https://en.wikipedia.org/wiki/Kernel_(image_processing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_filter_pipeline(img_name):\n",
    "    image = load_image(img_name, grayscale=True)\n",
    "    image = convert_image_c2f(image)\n",
    "\n",
    "    # Smooth the image with a gaussian blur to account for noise\n",
    "    ksize = (0, 0) # zeros cause kernel size to be determined by sigma\n",
    "    sigma = 10.0\n",
    "    image_blurred = cv2.GaussianBlur(image, ksize, sigma)\n",
    "    plt.imshow(image_blurred, cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "    kernel = np.array([[0, 1, 0],\n",
    "                       [1, -4, 1],\n",
    "                       [0, 1, 0]])\n",
    "    image_edges = cv2.filter2D(image_blurred, -1, kernel)\n",
    "    min_val = np.amin(image_edges)\n",
    "    range_val = np.amax(image_edges - min_val) \n",
    "    image_edges = (image_edges - min_val) / range_val\n",
    "    plt.imshow(image_edges, cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "    threshold = 0.70\n",
    "    image_thresholded = np.where(image_edges > threshold, 1.0, 0.0)\n",
    "    plt.imshow(image_thresholded, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in files[6:7]:\n",
    "    edge_filter_pipeline(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera calibration using a checkerboard (or chessboard)\n",
    "\n",
    "OpenCV uses the chessboard pattern to calibrate cameras.\n",
    "\n",
    "It's all very complex and detailed, but lets give it a go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants related to camera checkerboard calibration.\n",
    "\n",
    "# Checkerboard dimensions - number of internal corners (row, col)\n",
    "PATTERN_SIZE = (5, 7)\n",
    "PATTERN_NUM_POINTS = PATTERN_SIZE[0] * PATTERN_SIZE[1]\n",
    "\n",
    "# Pixel refinement termination criteria - accuracy and number of iterations\n",
    "CRITERIA = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chessboard_corners(img_name, reverse_image=False, debug=False):\n",
    "    \"\"\"\n",
    "    Tries to find the chessboard in the image given by img_name.\n",
    "    Flag determines if should plot/debug result\n",
    "    Returns:\n",
    "        - ret: boolean success value\n",
    "        - corners: subpixel coordinates of found corners, or None otherwise\n",
    "    \"\"\"\n",
    "    image = load_image(img_name, grayscale=True)\n",
    "    if reverse_image:\n",
    "        image = -image + 255\n",
    "    \n",
    "    ret, corners = cv2.findChessboardCorners(image, PATTERN_SIZE)\n",
    "    \n",
    "    if not ret:\n",
    "        if debug:\n",
    "            print(f\"cv2.findChessboardCorners failed for {img_name}\")\n",
    "        return False, None\n",
    "\n",
    "    corners2 = cv2.cornerSubPix(image, corners, (11, 11), (-1, -1), CRITERIA)\n",
    "    \n",
    "    if debug:\n",
    "        plt.imshow(image,cmap='gray')\n",
    "        plt.scatter(corners2[:,0,0], corners2[:,0,1], c='y', marker='.')\n",
    "        plt.show()\n",
    "\n",
    "    return ret, corners\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_image_paths = []\n",
    "image_shape = None\n",
    "for f in files[:]:\n",
    "    image = load_image(f)\n",
    "    if image.shape[0] < image.shape[1]:\n",
    "        image_shape = image.shape[:2]\n",
    "        horizontal_image_paths.append(f)\n",
    "    else:\n",
    "        print(image.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibration goal: Run cv2.calibrateCamera to get the intrinsic parameters\n",
    "# Construct a list of object points representing the internal corners of the checkerboard\n",
    "objp = np.zeros((PATTERN_NUM_POINTS, 3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:PATTERN_SIZE[0],0:PATTERN_SIZE[1]].T.reshape(-1, 2)\n",
    "\n",
    "# Requires the following parameters:\n",
    "objpoints = [] # list of objp, representing the 3d coordinates of our corners\n",
    "imgpoints = [] # List of the found 2d corners in each image plane\n",
    "image_size = image_shape[::-1]\n",
    "camera_matrix = None # Initial guess for camera matrix, and output param\n",
    "distortion_coeffs = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, corners = get_chessboard_corners(horizontal_image_paths[0], debug=True)\n",
    "print(f\"Got corners? {ret}\")\n",
    "print(f\"Corners got: {corners}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "average_delta_time = 0.0\n",
    "\n",
    "num_imgs = len(horizontal_image_paths)\n",
    "for f in horizontal_image_paths:\n",
    "    img_start_time = time.time()\n",
    "    ret, corners = get_chessboard_corners(f)\n",
    "    if ret:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "    img_end_time = time.time()\n",
    "    average_delta_time += (img_end_time - img_start_time)/num_imgs\n",
    "    print(f\"Image {f} took {img_end_time - img_start_time} seconds to get corners\")\n",
    "\n",
    "print(f\"Average time per image: {average_delta_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "calibration_start_time = time.time()\n",
    "ret, intrinsic_mat, distortion_mat, rotation_vecs, translation_vecs = \\\n",
    "    cv2.calibrateCamera(objpoints, imgpoints, image_size, camera_matrix, distortion_coeffs)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Calibration took {end_time - calibration_start_time} seconds\")\n",
    "print(f\"Total time: {average_delta_time * num_imgs + end_time - start_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(intrinsic_mat)\n",
    "print(distortion_mat)\n",
    "numpy_save(\"numpy/intrinsic_mat.npy\", intrinsic_mat)\n",
    "numpy_save(\"numpy/distortion_mat.npy\", distortion_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_image(horizontal_image_paths[1])\n",
    "h,  w = img.shape[:2]\n",
    "newcameramtx, roi = cv2.getOptimalNewCameraMatrix(intrinsic_mat, distortion_mat, (w,h), 1, (w,h))\n",
    "\n",
    "# undistort\n",
    "dst = cv2.undistort(img, intrinsic_mat, distortion_mat, None, newcameramtx)\n",
    "# crop the image\n",
    "x, y, w, h = roi\n",
    "dst = dst[y:y+h, x:x+w]\n",
    "print(\"Original\")\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "print(\"Undistorted\")\n",
    "plt.imshow(dst)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:lcnn]",
   "language": "python",
   "name": "conda-env-lcnn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
